---
layout: post
title: Deciphering Big Data
subtitle: Each post has a subtitle
categories: Modules
tags: [Github, Modules, Python]
---

### 1. A summary of the learning outcomes of the module
•	Study various concepts of big data, technologies, and data management to enable students to be able to identify and manage challenges associated with security risks and limitations.
	
• Critically analyse data wrangling problems and determine appropriate methodologies and tools in problem solving.

•	Explore different data types and formats. 

•	Explore and evaluate various data storage formats ranging from structured, quasi structured, semi structured, and unstructured formats.

•	Essentially examine different data collection methods and sources. 

•	Review methods to determine the integrity, reliability and readiness of data extracted and presented for pre-processing, cleaning, and usage.

•	Examine data exploration methods and analyse data for presentation in an organisation. 

•	Critically evaluate data readability, readiness, and longevity within the data Pipeline. 

•	Examine cloud services, for example the API (Application Programming Interfaces) and how this enables data interoperability and connectivity.

•	Examine and analyse the ideas and theoretical concepts underlying DBMS (Database Management Systems) Database Design and Modelling.

•	Conduct a deep analysis of the future of use of data and deciphering by examining some fundamental ideas and concepts of machine learning and how these concepts are applied in various methods in handling big data.

## 2.	The artefacts created during the module

### 2.1  Unit 1, 2 and 3: Collaboration discussion
Critically evaluate the rationale behind the Internet of Things (IOT), in the context of, highlighting the opportunities, limitations, risks and challenges associated with such a large-scale process of data collection.

### 2.1.1 Initial Post 
### Banking sector IoT data collection
Kopetz and Steiner  (2022) state that IoT is a  connection of physical things to the internet and this makes it possible to access remote sensor data and to control the physical world from a distance. The logic behind the IoT in a banking sector focused on enhancing operational efficiency, customer experience, data driven decision making and availability of real time data for business processes. This idea is tone down by significant limitations, risks and challenges. 

### Opportunities 
There is real-time data collection from ATMs, branches, mobile apps, and wearables to improve service delivery to customers. The IoT allows for integration of physical and digital banking environments, allowing banks to personalise services and optimise resource allocation. The IoT sensors and biometric devices improve surveillance and authentication, reducing fraud risk.

### Limitations
Despite the big improvement and  promises by the IoT in the banking sector, banks still face several constraints such as infrastructure gaps where in regions like South Africa, inconsistent connectivity, and power supply limit IoT deployment. Based on this, banks may struggle to process and extract actionable insights from vast, unstructured IoT data streams. Poorly cleaned data, missing data, and inaccurate data may lead to incorrect decision making in a banking environment.

### Risks 
Large-scale data collection introduces serious concerns in the IoT platform for example, privacy and consent where continuous monitoring of customer behaviour raises ethical questions about informed consent and data minimisation. The IoT devices are often poorly secured, creating entry points for attackers targeting financial systems. It is imperative that data cleaning to check for extreme values or outliers is effectively done because, if this matter is not dealt with before the analysis, the results will be skewed and unreliable.

### Challenges
The main challenge of IoT is digital inequality in financial exclusion which happens in rural or low income populations where lack of access to IoT platforms or poor connectivity is experienced. Proper and credible techniques must be used to deal with unit nonresponse from data collected thought the IoT platform. The ethical use of AI in leveraging IoT data for automated decision making for example loan approvals will result in high bias and discrimination if this is not properly managed.

### Conclusion
Larger scale IoT applications offer transformation opportunities in efficiency, innovation, and sustainability. To achieve these benefits, one requires a multidimensional strategy that addresses security, interoperability, scalability, regulatory compliance, and human factors. 

### References
Greengard, S., 2021. The internet of things. MIT press.

Hossein Motlagh, N., Mohammadrezaei, M., Hunt, J. and Zakeri, B., 2020. Internet of Things (IoT) and the energy sector. Energies, 13(2), p.494.

Kopetz, H. and Steiner, W., 2022. Internet of things. In Real-time systems: design principles for distributed embedded applications (pp. 325-341). Cham: Springer International Publishing.

Li, F., Li, F., Li, S. and Long, Y., 2020. Deciphering the recreational use of urban parks: Experiments using multi-source big data for all Chinese cities. Science of the Total Environment, 701, p.134896.

Sadhu, P.K., Yanambaka, V.P. and Abdelgawad, A., 2022. Internet of things: Security and solutions survey. Sensors, 22(19), p.7433.

### 2.1.2 Peer Response to Lenka Solarova
Thank you so much Lenka Solarova for such an insightful post that offers a thoughtful overview of the promise and pitfalls of large-scale data collection in IoT health monitoring. 

You emphasised the dual nature of IoT in healthcare, its capacity to save lives through continuous monitoring and its potential to transform public health through aggregated data. You also used examples such as smartwatches to foetal monitors as grounds for  discussion in real-world applications. Your post also made reference to predictive modelling and early diagnosis reflecting current trends in digital health innovation. You successfully managed to highlight the data lifecycle challenges from collection to cleaning underscoring that raw data alone is insufficient without robust preprocessing. This aligns with Mavrogiorgou et al. (2019), who stress the importance of data wrangling in time series health data.

While your post covers technical limitations and risks, some critical dimensions could be further explored such as ethical and regulatory oversight where you should engage with the ethical implications of health data collection because  IoT health devices often collect intimate biometric data, raising concerns about informed consent, data sovereignty, regulatory compliance and cybersecurity because, IoT health devices are often entry points for attackers. Huxley et al. (2020) warn that without robust encryption and authentication protocols, IoT health ecosystems remain dangerously exposed.

In conclusion, Solarova’s post provides a solid foundation for understanding the opportunities and challenges of IoT in health monitoring. However, a more critical lens reveals that technical complexity must be matched by ethical vigilance and regulatory alignment. 

### References

Hassanien A. E., Slowik A., and Snášel D. Intelligent Data Analysis for IoT Systems. Cham: Springer, pp. 133–153.

Huxley, C., Rosati, P., Lynn, T. and Cummins, M., 2020. The Internet of Things: Definitions, Key Concepts, and Reference Architectures. 

Mavrogiorgou, A., Giannakopoulos, G., & Tserpes, K., 2019. Data pre-processing and data wrangling techniques for IoT. 

Lynn T., Rosati P., Cummins M. and Huxley C. The Internet of Things: Key Applications and Protocols. Cham: Springer, pp.1–15.

### 2.1.3 Peer Response to Mattia Russo
The post offers a balanced overview of IoT’s promise, drawbacks, and Mattia Russo accurately defined IoT as a sensor-enabled network for data exchange, aligning with established literature like IBM’s technical framing (IBM, 2023) and recent reviews.

### Analysis and strengths of the post
(Thakur et al., 2023) argue that the integration of Deep Learning (DL) and the Internet of Things (IoT) has revolutionised technology in the twenty first century, enabling humans and machines to perform tasks more efficiently. Based on this statement, one can attest that the combination of DL and the IoT has resulted in significant advancements in technology by improving the efficiency, security, and user experience of IoT devices and systems. The post managed to clearly define the scope of IoT in the business world. The mentioning of education, smart cities, agriculture, and energy in the post reflects real-world IoT adoption trends. For instance, smart agriculture uses IoT for precision farming, while smart grids optimise energy distribution. The post correctly links IoT to big data analytics, emphasising operational efficiency and real-time decision-making which are core benefits supported by studies in industrial automation and smart infrastructure.
 
### Observed gaps and challenges in the post
There is citation ambiguity on the post such as the use of “(al., 2023)” and “Oclc.org, 2025” which lacks clarity and traceability. It should be noted that without full references, the credibility of claims, especially around ethics and data cleaning become weakened. Mattia also mentions algorithmic bias and transparency but does not explore how this manifest in IoT systems. For example, facial recognition in smart surveillance can reinforce racial bias if training data lacks diversity.

### Discussion on data quality and veracity
The emphasis on data cleaning is valid, but the post could have elaborated more by distinguishing between technical biases for example sensor drift and contextual biases for example socio-economic skew in data sources. The explanation of visual methods like boxplots and Q–Q plots in the post is very essential and useful, but it was going to be more beneficial if there were details on automated anomaly detection or AI assisted preprocessing of data, which are increasingly vital in large scale IoT systems.

### Conclusion
The IoT systems offer powerful opportunities for efficiency, personalisation, and data driven decision making across different sectors. Yet its full potential depends on overcoming challenges in scalability, ethics, data quality, and governance. These require strategic investment in skills, infrastructure, and responsible data practices.

### References

Khanna. A. and Kaur. S, “Internet of things (IoT), applications and challenges: A comprehensive review,” Wirel. Pers. Commun., vol. 114, pp. 1687–1762, 2020.

Mohsan S. A. H. et al., “Recent advances, future trends, applications and challenges of internet of underwater things (IoUT): A comprehensive review,” J. Mar. Sci. Eng., vol. 11, no. 1, p. 124, 2023.

Shaheen A., 2024 ‘The Internet of Things (IoT): A Comprehensive Review of Technologies, Applications, Challenges, and Future Trends’. Journal of Engineering and Computational Intelligence Review. Available at: https://jecir.com/index.php/jecir/article/view/11. (Accessed: 4 November 2025).

Thakur, D., Saini, J.K. and Srinivasan, S., 2023. DeepThink IoT: the strength of deep learning in internet of things. Artificial Intelligence Review, 56(12), pp.14663-14730.
Hassan, R.  et al., “Internet of Things and its applications: A comprehensive survey,” Symmetry, vol. 12, no. 10, p. 1674, 2020.

Verma H., Chauhan, Nm and Awasthi L. K., “A comprehensive review of ‘Internet of Healthcare Things’: Networking aspects, technologies, services, applications, challenges, and security concerns,” Comput. Sci. Rev., vol. 50, p. 100591, 2023.

### 2.1.4 Peer Response to Preh Muneer Abbasi
The post by Preh Muneer Abbasi provides a balanced overview of IoT’s opportunities and risks, and the cited works support the discussion in the post. In recent years, the Internet of Things (IoT) and Cyber-Physical-Systems (CPS) have gained significant attraction and are becoming increasingly omnipresent. By the year 2030, the installed base of IoT devices will grow to 500 billion worldwide according to (Lesch et al., 2023). This statement is supported by the evidence that both IoT and CPS find applications in many different domains, such as healthcare, energy and utilities, smart cities and communities, manufacturing, and transportation and distribution.

Preh’s post correctly identifies IoT’s core rationale, that it is connecting devices for continuous data collection and automation. This aligns with Marjani et al. (2017), who highlight IoT’s role in enabling smart cities, healthcare, and energy management through big data analytics. The mention of falling storage costs and ubiquitous sensors is valid and it reflects industry trends where cloud and edge computing architectures such as  Microsoft Azure IoT pipelines enable scalable data ingestion and analytics.

The observation that IoT data is heterogeneous and unstructured is accurate and this raises the need for data cleaning, integration, and standardisation before analytics can be effective. It is also noted that while challenges persist in IoT, recent advances in AI-driven analytics and edge computing have matured IoT applications beyond early-stage experimentation. The post rightly stresses security and privacy concerns, citing Huxley et al. (2020) where it indicates that IoT devices expand the attack surface, often suffering from weak encryption, outdated firmware, and poor patch management.

In conclusion, the post by Preh Muneer Abbasi provides a well-structured overview of IoT’s rationale, opportunities, and risks. It successfully highlights the transformative potential of IoT in domains such as smart cities, healthcare, and energy management, while also acknowledging the technical, security, and governance challenges that accompany large-scale data collection.

### References

Agarwal, S., Makkar, S., & Tran, D.-T. (2020). Privacy Vulnerabilities and Data Security Challenges in the IoT. CRC Press. https://doi.org/10.1201/9780429322969

Alsarray, Z. A., & Kadhim, S. A. (2025). Risks and Challenges of the Internet of Things: An Analytical Review. University of Information Technology and Communications

Huxley et al. (2020). A Review of IoT Security Challenges and Solutions. IEEE Xplore

Laghari, A. A., Li, H., Khan, A. A., Shoulin, Y., Karim, S., & Khani, M. A. (2024). IoT Applications Security Trends and Challenges. Springer

Lesch, V., Züfle, M., Bauer, A., Iffländer, L., Krupitzer, C. and Kounev, S., 2023. A literature review of IoT and CPS—What they are, and what they are not. Journal of Systems and Software, 200, p.111631.

Marjani, M., Nasaruddin, F., Gani, A., Karim, A., Hashem, I. A. T., Siddiqa, A., & Yaqoob, I. (2017). Big IoT Data Analytics: Architecture, Opportunities, and Open Research Challenges. IEEE Access, 5, 5247–5261

Microsoft Azure Architecture Center. (2025). Project 15 Open Platform IoT Sustainability. Microsoft Learn

### 2.1.5 Summary Post
The IoT connects physical devices to the internet, enabling real-time data access and remote control. For banks, IoT promises efficiency, customer-centric innovation, and data-driven decision-making. Yet, adoption requires careful navigation of infrastructure realities, regulatory compliance, and ethical considerations. (Fahmideh et al., 2023) state that the IoT platforms are key enablers for smart city initiatives, targeting the improvement of citizens’ quality of life and economic growth. As IoT platforms are dynamic, proactive, and heterogeneous socio-technical artefacts, systematic approaches are required for their development. Based on this statement from Fahmideh et al, there is limited information available from surveys or other sources indicating how IoT platforms are developed and maintained from the perspective of information system development process lifecycle. 

One peer response was received from Preh Muneer Abbasi for the collaboration discussion. The peer review response agreed with all the areas that were discussed in the initial post such as connectivity gaps, poor data quality, security measures. privacy safeguards, fairness controls, and infrastructure investment. Preh Muneer Abbasi suggested that “strategic initiatives are required to close the digital divide by investing in reliable networks and power supply, so that rural or low-income populations are not left behind”. This suggestion is very key in the advancement of the IoT platforms to address infrastructure challenges and digital inequality.

The summary learnings from unit 1 to 3 of the module includes big data, technologies associated with big data, and concepts underlying data management. A deep analysis in understand the four Vs of big data that include volume, velocity, variety, and veracity were also explored. Topics on different data types and formats and how these impact the way data is stored from different organisations were studied. An introduction to the implementation of Python routines and applications using APIs was achieved. Lastly, an in depth study of various data sources, data collection methods, and evaluating challenges associated with data collection process such as item nonresponse, unit nonresponse, missing data, outliers, and duplicate values was offered in the first 3 units of the module.

To sum up, it is apparent that IoT offers transformative opportunities across the world, but organisations must balance innovation with robust governance, cybersecurity frameworks, and compliance alignment to ensure sustainable adoption at all levels.

### References

Bandyopadhyay, D. and Sen, J., 2011. Internet of things: Applications and challenges in technology and standardization. Wireless personal communications, 58(1), pp.49-69.

Fahmideh, M. and Zowghi, D., 2020. An exploration of IoT platform development. Information Systems, 87, p.101409.

Holler, J., Tsiatsis, V., Mulligan, C., Karnouskos, S., Avesand, S. and Boyle, D., 2014. Internet of things. Academic Press.

Kumar, S., Kumar, K.A. and Raman, R., 2021, September. Internet of Things Security: Attacks, Solutions, Strengths and Limitations. In 2021 International 
Conference on Artificial Intelligence and Machine Vision (AIMV) (pp. 1-6). IEEE.

Li, S., Xu, L.D. and Zhao, S., 2015. The internet of things: a survey. Information systems frontiers, 17(2), pp.243-259.

Mukhopadhyay, S.C. and Suryadevara, N.K., 2014. Internet of things: Challenges and opportunities. Internet of things: Challenges and opportunities, pp.1-17.

### 2.2 Unit 3: Web Scraping
### 2.2.1 Web scraping
### Findings based on Python web scraping code
The Python script was specifically tailor for South African job boards such as Careers24 to align it with local compliance. The code is designed to scrape job postings for the keyword “Data Scientist” and it specifically looked at:

•	Job title as Data Scientist or Senior Data Scientist.

•	Company name for example Capitec Bank, Standard Bank or Deloitte.

•	Location went through different locations in the country, for example Cape Town in Western Cape or Johannesburg in Gauteng
The above attributes are stored in a Python list of dictionaries like:

python

[

  {
    "title": "Data Scientist",
    "company": "Capitec Bank",
    "location": "Cape Town, Western Cape"
  },
  
]

The output is in two formats as outlined below:

1.	JSON file (data_scientist_jobs.json)
   
•	This file format is easy for developers, analysts, or APIs to consume.

#### Example:

json
[

  {
    
    "title": "Data Scientist",
    "company": "Capitec Bank",
    "location": "Cape Town, Western Cape"
    
  }
  
]

2.	XML file (data_scientist_jobs.xml)
   
•	This file format is useful for legacy systems or compliance reporting.

#### Example:
xml

<Jobs>
  
  <Job>
    
    <Title>Data Scientist</Title>
    
    <Company>Capitec Bank</Company>
    
    <Location>Cape Town, Western Cape</Location>
    
  </Job>
  
</Jobs>

### 2.2.2 Important issues to note
1.	The actual findings depend on the live HTML structure of Careers24 or PNet at the time of scraping. If the site changes its CSS classes, for example job card or job title, the script must be updated to align with the changes.
   
2.	Some sites blocked scraping unless a user agent header is included on the code.
   
3.	It is noted that the Python script does not capture salary, posting date, or job description because these variables were not included on the selection list.
   
4.	I need skills in XML and HTML in order to develop an efficient script and be able to correctly interpret the results.

#### The Python script and results (JSON and XML) can be found on the link below.

https://colab.research.google.com/drive/18Y2WAtSWLQJ2y3JFn0yZU_Dbcvtt_oMP?usp=sharing

### 2.3 Unit 4: Data cleaning and transformation 
### 2.3.1 Lecturecast activities and results 
#### Exercise 1
Identify the raw dataset from GitHub as mn.csv and mn_headers.csv and download them into the desktop.
#### 2.3.2 Create mn.csv
Manually creating the mn.csv file that should contain only the data rows, without headers or variables.

#### Steps:

o	Open the raw dataset in a spreadsheet.

o	Delete the first line (the header row).

o	Save the remaining rows as mn.csv.
 <img width="1036" height="593" alt="image" src="https://github.com/user-attachments/assets/cf1192b5-a544-471d-8a16-b4a399cda509" />

#### 2.3.3 Create mn_headers.csv
Manually creating the mn_headers.csv that should contain only the header row.

#### Steps:

o	Copy the first line (the header row) from the raw dataset.

o	Paste it into a new file.

o	Save that file as mn_headers.csv.
 <img width="1020" height="553" alt="image" src="https://github.com/user-attachments/assets/057ac49a-81a2-4a6b-93e9-14bcec0e8f7f" />

The Python example that reads the two files (mn.csv and mn_headers.csv) separately and then combines them into a single DataFrame for analysis is outlined below.
#### Python script
import pandas as pd

Step 1: Load the headers

headers = pd.read_csv("mn_headers.csv", header=None).iloc[0].tolist()

Step 2: Load the data without headers

data = pd.read_csv("mn.csv", header=None)

Step 3: Assign headers to the data

data.columns = headers

Step 4: Inspect the combined DataFrame

print(data.head())

### 2.4 Unit 5: Seminar
### 2.4.1 Title: Case Study on data investigations
### Western African Ebola virus epidemic (2013–2016) 
•	The Western African Ebola virus epidemic (2013–2016) was the most widespread outbreak of Ebola virus disease (EVD) in history.

•	Causing major loss of life and socioeconomic disruption in the region, mainly in Guinea, Liberia, and Sierra Leone.

•	The  first cases were recorded in Guinea in December 2013.

•	Later, the disease spread to neighbouring Liberia and Sierra Leone, with minor outbreaks occurring elsewhere.

•	It caused significant mortality, with the case fatality rate reported which was initially considered, while the rate among hospitalised patients was 57–59%.

•	The final numbers 28,616 people, including 11,310 deaths, for a case-fatality rate of 40%.

### 2.4.2 Data analysis and results
#### Python code

import pandas as pd

Load the dataset
   
df = pd.read_csv("ebola_2014_2016_clean.csv")

Missing values per country per column

missing_values = df.groupby("Country").apply(lambda x: x.isnull().sum())

print("=== Missing Values per Country per Column ===")

print(missing_values)

print("\n")

Cumulative totals (cases and deaths) per country

cumulative_totals = df.groupby("Country")[[

    "Cumulative no. of confirmed, probable and suspected cases",
    
    "Cumulative no. of confirmed, probable and suspected deaths"
    
]].sum()

print("=== Cumulative Totals per Country ===")

print(cumulative_totals)

print("\n")

Mean and Standard Deviation per country
 
stats = df.groupby("Country")[[

    "Cumulative no. of confirmed, probable and suspected cases",
   
    "Cumulative no. of confirmed, probable and suspected deaths"
   
]].

agg (["mean", "std"])

print("=== Mean and Standard Deviation per Country ===")

print(stats)

### 2.4.3 Results

<img width="877" height="594" alt="image" src="https://github.com/user-attachments/assets/61bebee1-32ba-4161-b151-88f2efcfac27" />

Spain, United States, and United Kingdom are outliers in the dataset since the data is based on Western African Ebola virus epidemic.

<img width="747" height="318" alt="image" src="https://github.com/user-attachments/assets/816ae7be-f4c2-4331-9085-a0e651d73d8b" />

Mali, Guinea, Liberia, Nigeria, and Sierra Leone had the highest percentage of deaths based on recorded cases and deaths while Senegal had no deaths from the three reported cases.

<img width="888" height="284" alt="image" src="https://github.com/user-attachments/assets/bf919138-0fd4-4301-a45e-fd8696d011d3" />

### 2.5 Unit 6: Assignment Project Report on a database design
A team of 4 students was created to position themselves as a team of Software Consultants and Developers contracted to design and build a logical database. The team had to choose an application and the client profile for the project. 

Team was expected to prepare and deliver a design report of the intended development work for the client organisation. The design report had to capture the following:

•	Logical design => data items/entities, attributes of the data items chosen, relationships and associations. Identify and explain the data types used and data formats selected.

•	Produce a proposal of the database build, creating an intended database model design. The team was expected to propose a database management system that will be used for the build, considering the client requirements of storage, user access, and the manipulation and retrieval of data within the proposed database.

•	The team was also expected to critically evaluate the data management pipeline process with regards to discussing the capturing of the data used and detailing its source, documenting how you implemented data cleaning techniques and the stages that have been carried out during the cleaning process.

The proposal document was developed and submitted for grading by 01 December 2025 by the Project and Research Lead, Database Designer, Data Manager, and Data Dictionary Analyst.

### 2.6 Unit 7: The Normalisation and database built tasks including the results
Use the DBD_PCOM7E table provided to execute the normalisation task and then use the tables to design a database.
### 2.6.1 Normalisation and results
### 2.6.1.1 First Normal Form (1NF)
#### Rules:

•	Eliminate repeating groups.

•	Ensure atomic values (no multi-valued attributes).

•	Each row must have a unique primary key.

#### Action taken: Separate each course taken by a student into its own row.

<img width="888" height="648" alt="image" src="https://github.com/user-attachments/assets/6762778c-3270-41b1-bfcd-cac8d6e4a2e3" />

### 2.6.1.2  Second Normal Form (2NF)
#### Rules:

•	Must already have passed the 1NF stage.

•	Remove partial dependencies (non-key attributes depending only on part of a composite key). 

#### Action taken: Split the table into separate tables.

Students (student details independent of courses). 

Courses (course details independent of students).

Enrolments (linking students to courses, exam boards, teachers, and scores).

<img width="654" height="369" alt="image" src="https://github.com/user-attachments/assets/587a2c9a-85b3-48d0-bd37-81147a3928ab" />


<img width="454" height="269" alt="image" src="https://github.com/user-attachments/assets/9a65e8e1-389b-4cda-8586-bec6d303a696" />


<img width="789" height="408" alt="image" src="https://github.com/user-attachments/assets/7950aac6-6788-4fff-9b9b-d5b1e154ad2b" />

### 2.6.1.3 Third Normal Form (3NF)
#### Rules:

•	Must already have passed the 2NF stage.

•	Remove transitive dependencies (non-key attributes depending on other non-key attributes).

#### Action taken: Divide the table into five separate tables.

•	Teacher Name depends on Course (not directly on Student).

•	Exam Board depends on Course and so, there is a need to separate Teachers and Exam Boards into their own tables.


<img width="584" height="235" alt="image" src="https://github.com/user-attachments/assets/dcdb03e7-695f-4e4e-9398-0755ef291f9c" />


<img width="584" height="235" alt="image" src="https://github.com/user-attachments/assets/8344a366-5561-4d58-aa67-5e7b76465d13" />


<img width="584" height="235" alt="image" src="https://github.com/user-attachments/assets/0e0ffd18-d3fe-46e9-ab0e-806b710f7f67" />


<img width="584" height="235" alt="image" src="https://github.com/user-attachments/assets/af10f7d6-8324-4be1-a864-4d9e29eb8b1f" />


<img width="769" height="402" alt="image" src="https://github.com/user-attachments/assets/da16b3c2-01ad-475b-89c6-7417fe662f58" />


### 2.6.2 The database design
Microsoft Access database was selected to design the database for this exercise, which is a desktop-based relational database management system (RDBMS) that helps users create, manage, and analyse structured data using tables, queries, forms, and reports.https://github.com/Velim73285-Star/Velim73285-Star.GitHub.io/blob/main/_posts/2025-11-09-Second-Module-Post.md

<img width="888" height="467" alt="image" src="https://github.com/user-attachments/assets/b5fe6d0e-ab5a-4faf-a211-9394501f1645" />


<img width="889" height="798" alt="image" src="https://github.com/user-attachments/assets/2ad48efa-9e51-44ac-97fe-c79893e295bc" />

### 2.7 Unit 8, 9 and 10: Collaboration discussion
To be completed

### 2.8 Unit 9: Seminar activity

Complete an example with storing data in a relational database. The example uses SQLite and includes the following parts:

• Installing SQLite and setting a relational database with Python.
 
• Saving the cleaned UNICEF dataset into the SQLite database.

** Work done in Python to create the SQlite DB

import pandas as pd

import sqlite3

** Load the Ms Excel dataset

df = pd.read_excel("Mortality_rate_Final.xlsx")

** Connect to SQLite database

conn = sqlite3.connect("unicef.db")

** Save dataset into SQLite (replace table Mortality_rate_Final.xlsx with mortality_data)

df.to_sql("mortality_data", conn, if_exists="replace", index=False)

import sqlite3

import pandas as pd

** Connect to database called Unicef

conn = sqlite3.connect("unicef.db")

** Create a cursor object: A cursor object in Python is an interface to interact with a database. it allows one to execute SQL queries, fetch results, and manage transactions through a connection. It acts as a bridge between your Python code and the database engine, whether you’re using SQLite, MySQL, or another supported database

cursor = conn.cursor()

** Querying the database: Example 1: Average mortality rate per country 

cursor.execute("""

SELECT Region, AVG(mortality_rate) AS avg_rate

FROM mortality_data

GROUP BY Region

ORDER BY avg_rate ASC

""")

rows = cursor.fetchall()

print("Average mortality rate per country:")

for row in rows:

    print(row)

import sqlite3

import pandas as pd

** Connect to the database

conn = sqlite3.connect("unicef.db")

** Create a cursor

cursor = conn.cursor()

** Example 2: Calculate the stats on a variable called Mortality_Rate

import sqlite3

import pandas as pd

** Connect to the database

conn = sqlite3.connect("unicef.db")

** Use table 'mortality_data' and numeric variable 'Mortality_Rate'

query = "SELECT Year, Mortality_Rate FROM mortality_data"

df = pd.read_sql_query(query, conn)

** Group by year and calculate the stats

stats = df.groupby("Year")["Mortality_Rate"].agg(

    mean="mean",
    
    std="std",
    
    range=lambda x: x.max() - x.min()
)

print(stats)

** Close the database connection

conn.close()

## 3.	What exactly have I learnt and how?
### 3.1 What have I learnt from this module?
To be completed

### 3.2 The how part of learning the above
To be completed

## 4.	Professional skills gained and enhanced as a result of the module 
To be completed
